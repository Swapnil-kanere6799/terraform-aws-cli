name: eventstore/Cross-Region-Multi-Account-Migration-Using-S3-Stream-Automation

run-name: eventstore/Cross-region-Multi-Account-Migration-from-${{ inputs.SourceStackName }}-to-${{ inputs.DestinationStackName }}-${{ github.run_number }}

on:
  workflow_dispatch:
    inputs:
      RestartDestinationEventstore:
        type: choice
        description: Restart Destination Eventstore
        required: true
        default: "False"
        options:
          - "True"
          - "False"

      AccountId:
        type: string
        description: Accounts to be migrated, Example:- 1733818752,1733818753
        required: true
        default: ""

      JobIdentifier:
        type: string
        description: Job identifier
        required: true
        default: ""

      SourceStackName:
        type: string
        description: Name of the source stack
        required: true
        default: ""

      DestinationStackName:
        type: string
        description: Name of the destination stack
        required: true
        default: ""

      RedisStackName:
        type: string
        description: Name of the destination Redis stack
        required: true
        default: ""

      CatalogStoreStackName:
        type: string
        description: Name of the destination CatalogStore stack
        required: true
        default: ""

      DisableSafetyChecks:
        type: boolean
        default: false
        description: Disable Safety Checks of migration

env:
  ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true

jobs:
  setup-job-environment:
    runs-on: ubuntu-latest
    steps:
      - name: Generate github token
        id: generate-github-token
        uses: tibdex/github-app-token@v2
        with:
          app_id: ${{ secrets.CLEVERTAP_SNE_BOT_ID }}
          private_key: ${{ secrets.CLEVERTAP_SNE_BOT_PRIVATE_ACCESS_KEY }}

      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Checkout Cloudformation repo
        uses: actions/checkout@v3
        with:
          repository: CleverTap-SNE/Cloudformation
          path: cloudformation
          token: ${{ steps.generate-github-token.outputs.token }}

      - name: Get stack prefix of source
        id: get-source-stack-prefix
        run: |
          set -euxo pipefail
          stack_prefix=$(echo "${{ inputs.SourceStackName }}" | cut -d '-' -f1)
          echo "SOURCE_STACK_PREFIX=${stack_prefix}" >> $GITHUB_OUTPUT    

      - name: Get stack prefix of destination
        id: get-destination-stack-prefix
        run: |
          set -euxo pipefail
          stack_prefix=$(echo "${{ inputs.DestinationStackName }}" | cut -d '-' -f1)
          echo "DESTINATION_STACK_PREFIX=${stack_prefix}" >> $GITHUB_OUTPUT           

      - name: Get stack region of source
        id: get-source-stack-region
        run: |
          set -euxo pipefail
          region=$(./scripts/utils/get_stack_region.bash ${{ steps.get-source-stack-prefix.outputs.SOURCE_STACK_PREFIX }})
          echo "SOURCE_REGION=${region}" >> $GITHUB_OUTPUT 

      - name: Get stack region of destination
        id: get-destination-stack-region
        run: |
          set -euxo pipefail
          region=$(./scripts/utils/get_stack_region.bash ${{ steps.get-destination-stack-prefix.outputs.DESTINATION_STACK_PREFIX }})
          echo "DESTINATION_REGION=${region}" >> $GITHUB_OUTPUT           

      - name: Get stack instance count of source
        id: get-source-stack-instance-count
        working-directory: cloudformation
        run: |
          set -euxo pipefail
          stack_prefix=${{ steps.get-source-stack-prefix.outputs.SOURCE_STACK_PREFIX }}
          instance_count=$(jq -r '.[] | select(.Name == "${{ inputs.SourceStackName }}") | .InstanceCount' eventstore/$stack_prefix/clusters.json)
          echo "SOURCE_INSTANCE_COUNT=$instance_count" >> $GITHUB_OUTPUT

      - name: Get source stack start ip
        id: get-source-stack-start-ip
        working-directory: cloudformation
        run: |
          set -euxo pipefail
          stack_prefix=${{ steps.get-source-stack-prefix.outputs.SOURCE_STACK_PREFIX }}
          start_ip=$(jq -r '.[] | select(.Name == "${{ inputs.SourceStackName }}") | .StartIp' eventstore/$stack_prefix/clusters.json)
          echo "SOURCE_START_IP=$start_ip" >> $GITHUB_OUTPUT

      - name: Get stack instance count of destination
        id: get-destination-stack-instance-count
        working-directory: cloudformation
        run: |
          set -euxo pipefail
          stack_prefix=${{ steps.get-destination-stack-prefix.outputs.DESTINATION_STACK_PREFIX }}
          instance_count=$(jq -r '.[] | select(.Name == "${{ inputs.DestinationStackName }}") | .InstanceCount' eventstore/$stack_prefix/clusters.json)
          echo "DESTINATION_INSTANCE_COUNT=$instance_count" >> $GITHUB_OUTPUT

      - name: Get destination stack start ip
        id: get-destination-stack-start-ip
        working-directory: cloudformation
        run: |
          set -euxo pipefail
          stack_prefix=${{ steps.get-destination-stack-prefix.outputs.DESTINATION_STACK_PREFIX }}
          start_ip=$(jq -r '.[] | select(.Name == "${{ inputs.DestinationStackName }}") | .StartIp' eventstore/$stack_prefix/clusters.json)
          echo "DESTINATION_START_IP=$start_ip" >> $GITHUB_OUTPUT

      - name: convert account ids into proper json string
        id: convert-account-id-into-json-string
        run: |
          set -euxo pipefail
          account_ids="${{ inputs.AccountId }}"
          output=$(echo "$account_ids" | sed 's/\([^,]*\)/\\\\\\\"\1\\\\\\\"/g')
          echo "ACCOUNT_IDS=${output}" >> $GITHUB_OUTPUT          

      - name: Get SSM Document Names
        id: get-ssm-documents
        run: |
          set -euxo pipefail
          # Fetch all SSM document names
          source_documents=$(aws ssm list-documents --region ${{ steps.get-source-stack-region.outputs.SOURCE_REGION }} --filters Key=Owner,Values=Self --query "DocumentIdentifiers[*].Name" --output json)
          destination_documents=$(aws ssm list-documents --region ${{ steps.get-destination-stack-region.outputs.DESTINATION_REGION }} --filters Key=Owner,Values=Self --query "DocumentIdentifiers[*].Name" --output json)
          # Extract each document name
          source_document_name=$(echo "$source_documents" | jq -r '.[] | select(contains("Cross-Region-Source-Account-Migrator-MoveShardedMultiAccountUsingS3StreamAutomation"))')
          destination_document_name=$(echo "$destination_documents" | jq -r '.[] | select(contains("Cross-Region-Destination-Account-Migrator-MoveShardedMultiAccountUsingS3StreamAutomation"))')
          underscore_document_name=$(echo "$source_documents" | jq -r '.[] | select(contains("SsmDocument-MarkingMultipleAccountWithUnderscoreEventstoreSsmDocument"))')
          source_restart_nb_document_name=$(echo "$source_documents" | jq -r '.[] | select(contains("SsmDocument-ExecuteStopNotificationBackendSsmDocument"))')
          destination_restart_nb_document_name=$(echo "$destination_documents" | jq -r '.[] | select(contains("SsmDocument-ExecuteStopNotificationBackendSsmDocument"))')
          
          echo "SOURCE_DOCUMENT_NAME=${source_document_name}" >> $GITHUB_OUTPUT
          echo "DESTINATION_DOCUMENT_NAME=${destination_document_name}" >> $GITHUB_OUTPUT
          echo "UNDERSCORE_DOCUMENT_NAME=${underscore_document_name}" >> $GITHUB_OUTPUT
          echo "SOURCE_RESTART_NB_DOCUMENT_NAME=${source_restart_nb_document_name}" >> $GITHUB_OUTPUT
          echo "DESTINATION_RESTART_NB_DOCUMENT_NAME=${destination_restart_nb_document_name}" >> $GITHUB_OUTPUT
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    

    outputs:
      SOURCE_STACK_PREFIX: ${{ steps.get-source-stack-prefix.outputs.SOURCE_STACK_PREFIX }}
      DESTINATION_STACK_PREFIX: ${{ steps.get-destination-stack-prefix.outputs.DESTINATION_STACK_PREFIX }}
      SOURCE_REGION: ${{ steps.get-source-stack-region.outputs.SOURCE_REGION }}
      DESTINATION_REGION: ${{ steps.get-destination-stack-region.outputs.DESTINATION_REGION }}
      SOURCE_DOCUMENT_NAME: ${{ steps.get-ssm-documents.outputs.SOURCE_DOCUMENT_NAME }}
      DESTINATION_DOCUMENT_NAME: ${{ steps.get-ssm-documents.outputs.DESTINATION_DOCUMENT_NAME }}
      UNDERSCORE_DOCUMENT_NAME: ${{ steps.get-ssm-documents.outputs.UNDERSCORE_DOCUMENT_NAME }}
      SOURCE_RESTART_NB_DOCUMENT_NAME: ${{ steps.get-ssm-documents.outputs.SOURCE_RESTART_NB_DOCUMENT_NAME }}
      DESTINATION_RESTART_NB_DOCUMENT_NAME: ${{ steps.get-ssm-documents.outputs.DESTINATION_RESTART_NB_DOCUMENT_NAME }}
      SOURCE_INSTANCE_COUNT: ${{ steps.get-source-stack-instance-count.outputs.SOURCE_INSTANCE_COUNT }}
      SOURCE_START_IP: ${{ steps.get-source-stack-start-ip.outputs.SOURCE_START_IP }}
      DESTINATION_INSTANCE_COUNT: ${{ steps.get-destination-stack-instance-count.outputs.DESTINATION_INSTANCE_COUNT }}
      DESTINATION_START_IP: ${{ steps.get-destination-stack-start-ip.outputs.DESTINATION_START_IP }}
      ACCOUNT_IDS: ${{ steps.convert-account-id-into-json-string.outputs.ACCOUNT_IDS }}

  execute-safety-check-before-migration:
    runs-on: ubuntu-latest
    needs: setup-job-environment
    steps:
      - name: Generate github token
        id: generate-github-token
        uses: tibdex/github-app-token@v1.8.0
        with:
          app_id: ${{ secrets.CLEVERTAP_SNE_BOT_ID }}
          private_key: ${{ secrets.CLEVERTAP_SNE_BOT_PRIVATE_ACCESS_KEY }}

      - name: Checkout Cloudformation-Configuration
        if: inputs.DisableSafetyChecks == false
        uses: actions/checkout@v3
        with:
          repository: CleverTap-SNE/Cloudformation-Configuration
          path: cloudformation/configuration
          token: ${{ steps.generate-github-token.outputs.token }}

      - name: Compare source and destination tags
        if: inputs.DisableSafetyChecks == false
        working-directory: cloudformation/configuration
        run: |
          set -euxo pipefail
          source_tags=$(jq -r '.["${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"] | [.["${{ inputs.SourceStackName }}-Eventstore-Service"].ContainerTag, .["${{ inputs.SourceStackName }}-Nb-Service"].ContainerTag, .["${{ inputs.SourceStackName }}-RealtimeExports-Service"].ContainerTag] | join(",")' values.json)
          destination_tags=$(jq -r '.["${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}"] | [.["${{ inputs.DestinationStackName }}-Eventstore-Service"].ContainerTag, .["${{ inputs.DestinationStackName }}-Nb-Service"].ContainerTag, .["${{ inputs.DestinationStackName }}-RealtimeExports-Service"].ContainerTag] | join(",")' values.json) 
          if [ "$source_tags" != "$destination_tags" ]; then
            echo "Tags do not match. Failing the workflow."
            exit 1
          else
            echo "Tags match."
          fi


  execute-eventstore-mongo-data-migration:
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
    uses: ./.github/workflows/eventstore-mongo-data-simulation.yml
    secrets: inherit
    with:
      AccountId: ${{ inputs.AccountId }}
      SourceStackName: ${{ inputs.SourceStackName }}
      DestinationStackName: ${{ inputs.DestinationStackName }}
      RedisStackName: ${{ inputs.RedisStackName }}
      CatalogStoreStackName: ${{ inputs.CatalogStoreStackName }}
      MongoDataSimulation: false

  wait-for-mongo-data-migration-complete:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
    environment: wait-for-approval
    steps:
      - name: Got approval hence proceeding further
        run: |
          set -euxo pipefail
          echo "Mongo Data migration complete"
      

  execute-disable-cron-jobs:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
    steps:
      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Install Python Requirements
        run: |
          set -euxo pipefail
          python3 -m venv prod-venv
          source prod-venv/bin/activate
          pip3 install requests argparse boto3      

      - name: Set Up AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.setup-job-environment.outputs.SOURCE_REGION }}

      - name: Execute SSM Command on ${{ inputs.SourceStackName }}
        run: |
          command_id=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.SourceStackName }} \
                      Key=tag:role,Values=eventstore \
            --comment "Run curl command on all instances" \
            --parameters "{\"commands\":[\"curl -X POST -H 'Content-Type:application/json' -d '{\\\"accounts\\\":[${{ needs.setup-job-environment.outputs.ACCOUNT_IDS }}]}' http://127.0.0.1:8080/pause-eventstore/initialise_pause\"]}" \
            --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
            --output text \
            --max-errors "100%" \
            --max-concurrency "100%" \
            --query "Command.CommandId")
          
          
          echo "SSM Command ID: $command_id"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"
          python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --command-id "$command_id" --output "true" --message "success" 

  wait-for-2-hour-and-approve-this:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
    environment: wait-for-approval
    steps:
      - name: Got approval hence proceeding further
        run: |
          set -euxo pipefail
          echo "2 hours wait complete"

  execute-stop-ingestion-and-validate-pausing-account:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
    steps:
      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Install Python Requirements
        run: |
          set -euxo pipefail
          python3 -m venv prod-venv
          source prod-venv/bin/activate
          pip3 install requests argparse boto3

      - name: Set Up AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.setup-job-environment.outputs.SOURCE_REGION }}

      - name: Execute SSM Command on ${{ inputs.SourceStackName }} to stop ingestion
        run: |
          command_id=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.SourceStackName }} \
                      Key=tag:role,Values=eventstore \
            --comment "Run curl command on all instances" \
            --parameters "{\"commands\":[\"curl -X POST -H 'Content-Type:application/json' -d '{\\\"accounts\\\":[${{ needs.setup-job-environment.outputs.ACCOUNT_IDS }}]}' http://127.0.0.2:8080/pause-eventstore/pause\"]}" \
            --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
            --output text \
            --max-errors "100%" \
            --max-concurrency "100%" \
            --query "Command.CommandId")


          echo "SSM Command ID: $command_id"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"
          python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --command-id "$command_id" --output "true" --message "success"

      - name: Execute SSM Command on ${{ inputs.SourceStackName }} to check for pausing account
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 2
          max_attempts: 300
          shell: bash
          command: |
            command_id=$(aws ssm send-command \
              --document-name "AWS-RunShellScript" \
              --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.SourceStackName }} \
                        Key=tag:role,Values=eventstore \
              --comment "Run curl command on all instances" \
              --parameters "{\"commands\":[\"curl -X POST -H 'Content-Type:application/json' -d '{}' http://127.0.0.2:8080/pause-eventstore/get_pausing\"]}" \
              --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
              --output text \
              --max-errors "100%" \
              --max-concurrency "100%" \
              --query "Command.CommandId")
            
            
            echo "SSM Command ID: $command_id"
            echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"
            python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --command-id "$command_id" --output "true" --message "No pausing account"

  execute-source-account-migration-automation:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
    steps:
      - name: Set Up AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.setup-job-environment.outputs.SOURCE_REGION }}

      - name: Copy accounts from source to s3 via ssm automation
        run: |
          ExecutionId=$(aws ssm start-automation-execution \
              --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
              --document-name "${{ needs.setup-job-environment.outputs.SOURCE_DOCUMENT_NAME }}" \
              --parameters '{"AccountId":["${{ inputs.AccountId }}"], "SourceEventstoreStartInstanceIp":["${{ needs.setup-job-environment.outputs.SOURCE_START_IP }}"], "JobIdentifier":["${{ inputs.JobIdentifier }}"], "SourceStackName":["${{ inputs.SourceStackName }}"], "NumberOfSourceEventstoreInstances":["${{ needs.setup-job-environment.outputs.SOURCE_INSTANCE_COUNT }}"]}' \
              --output text \
              --query "AutomationExecutionId")
          echo "Command Response: $ExecutionId"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/automation/execution/$ExecutionId?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"

  wait-for-copy-all-account-to-s3-and-approve-this:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
    environment: wait-for-approval
    steps:
      - name: Got approval hence proceeding further
        run: |
          set -euxo pipefail
          echo "Copied all data to s3"

  execute-destination-account-migration-automation:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
      - wait-for-copy-all-account-to-s3-and-approve-this
    steps:
      - name: Set Up AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}

      - name: Copy accounts from s3 to destination via ssm automation
        run: |
          ExecutionId=$(aws ssm start-automation-execution \
              --region ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }} \
              --document-name "${{ needs.setup-job-environment.outputs.DESTINATION_DOCUMENT_NAME }}" \
              --parameters '{"restartDestinationEventstore":["${{ inputs.RestartDestinationEventstore }}"], "AccountId":["${{ inputs.AccountId }}"], "SourceEventstoreStartInstanceIp":["${{ needs.setup-job-environment.outputs.SOURCE_START_IP }}"], "DestinationEventstoreStartInstanceIp":["${{ needs.setup-job-environment.outputs.DESTINATION_START_IP }}"], "DestinationStackName":["${{ inputs.DestinationStackName }}"], "NumberOfDestinationEventstoreInstances":["${{ needs.setup-job-environment.outputs.DESTINATION_INSTANCE_COUNT }}"], "JobIdentifier":["${{ inputs.JobIdentifier }}"]}' \
              --output text \
              --query "AutomationExecutionId")
          echo "Command Response: $ExecutionId"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}.console.aws.amazon.com/systems-manager/automation/execution/$ExecutionId?region=${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}"

  wait-for-copy-all-accounts-to-destination-and-approve-this:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
      - wait-for-copy-all-account-to-s3-and-approve-this
      - execute-destination-account-migration-automation
    environment: wait-for-approval
    steps:
      - name: Got approval hence proceeding further
        run: |
          set -euxo pipefail
          echo "Copy all data to destination"

  validate-account-is-migrated-or-not:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
      - wait-for-copy-all-account-to-s3-and-approve-this
      - execute-destination-account-migration-automation
      - wait-for-copy-all-accounts-to-destination-and-approve-this
    steps:
      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Install Python Requirements
        run: |
          set -euxo pipefail
          python3 -m venv prod-venv
          source prod-venv/bin/activate
          pip3 install requests argparse boto3  

      - name: Check Size of accounts- ${{ inputs.AccountId }} on source
        id: get-source-account-size
        run: |
          set -euxo pipefail
          source prod-venv/bin/activate         
          python3 ./scripts/eventstore/check-account-size.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --stack "${{ inputs.SourceStackName }}" --account-ids "${{ inputs.AccountId }}" > source_account_size.json
          source_account_size=$(jq -c . source_account_size.json)
          echo "SOURCE_ACCOUNT_SIZE=${source_account_size}" >> $GITHUB_OUTPUT 
          python3 ./scripts/eventstore/check-account-size.py --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} --stack ${{ inputs.SourceStackName }} --account-ids ${{ inputs.AccountId }} --is-tmp > source_tmp_account_size.json
          source_tmp_account_size=$(jq -c . source_tmp_account_size.json)
          echo "SOURCE_TMP_ACCOUNT_SIZE=${source_tmp_account_size}" >> $GITHUB_OUTPUT
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Check Size of account- ${{ inputs.AccountId }} on destination
        id: get-destination-account-size
        run: |
          set -euxo pipefail
          source prod-venv/bin/activate
          python3 ./scripts/eventstore/check-account-size.py --region ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }} --stack ${{ inputs.DestinationStackName }} --account-ids ${{ inputs.AccountId }} > destination_account_size.json
          destination_account_size=$(jq -c . destination_account_size.json)
          echo "DESTINATION_ACCOUNT_SIZE=${destination_account_size}" >> $GITHUB_OUTPUT
          python3 ./scripts/eventstore/check-account-size.py --region ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }} --stack ${{ inputs.DestinationStackName }} --account-ids ${{ inputs.AccountId }} --is-tmp > destination_tmp_account_size.json
          destination_tmp_account_size=$(jq -c . destination_tmp_account_size.json)
          echo "DESTINATION_TMP_ACCOUNT_SIZE=${destination_tmp_account_size}" >> $GITHUB_OUTPUT
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Check Account Is Migrated Completely
        run: |
          set -euxo pipefail
          source prod-venv/bin/activate
          echo '${{ steps.get-source-account-size.outputs.SOURCE_ACCOUNT_SIZE }}' | jq -c . > source.json
          echo '${{ steps.get-destination-account-size.outputs.DESTINATION_ACCOUNT_SIZE }}' | jq -c . > destination.json
          echo '${{ steps.get-source-account-size.outputs.SOURCE_TMP_ACCOUNT_SIZE }}' | jq -c . > source_tmp.json
          echo '${{ steps.get-destination-account-size.outputs.DESTINATION_TMP_ACCOUNT_SIZE }}' | jq -c . > destination_tmp.json
          python3 ./scripts/eventstore/compare-accounts-size.py --source source.json --destination destination.json
          echo "Checking for tmp directory"
          python3 ./scripts/eventstore/compare-accounts-size.py --source source_tmp.json --destination destination_tmp.json

  execute-post-account-migration-steps:
    runs-on: ubuntu-latest
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
      - wait-for-copy-all-account-to-s3-and-approve-this
      - execute-destination-account-migration-automation
      - wait-for-copy-all-accounts-to-destination-and-approve-this
      - validate-account-is-migrated-or-not
    steps:
      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Install Python Requirements
        run: |
          set -euxo pipefail
          python3 -m venv prod-venv
          source prod-venv/bin/activate
          pip3 install requests argparse boto3

      - name: activate account on destination ${{ inputs.DestinationStackName }} on all shards
        run: |
          set -euxo pipefail
          IFS=',' read -r -a ACCOUNT_ID_ARR <<< "${{ inputs.AccountId }}"
          for SINGLE_ACCOUNT in "${ACCOUNT_ID_ARR[@]}"
          do
              echo "Processing Account: $SINGLE_ACCOUNT"
              CURL_COMMAND="curl \"http://127.0.0.1:8080/acc/act?a=${SINGLE_ACCOUNT}&f=true\""
              command_id=$(aws ssm send-command \
                --document-name "AWS-RunShellScript" \
                --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.DestinationStackName }} \
                          Key=tag:role,Values=eventstore \
                --comment "Run curl command on all instances" \
                --parameters commands="[\"${CURL_COMMAND//\"/\\\"}\"]" \
                --region ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }} \
                --output text \
                --max-errors "100%" \
                --max-concurrency "100%" \
                --query "Command.CommandId")

              echo "SSM Command ID: $command_id"
              echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}"
              python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}" --command-id "$command_id" --output "false"
          done
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Reboot NB on Source
        run: |
          command_id=$(aws ssm send-command \
                --document-name "${{ needs.setup-job-environment.outputs.SOURCE_RESTART_NB_DOCUMENT_NAME }}" \
                --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.SourceStackName }} \
                          Key=tag:role,Values=eventstore \
                --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
                --output text \
                --max-errors "100%" \
                --max-concurrency "100%" \
                --query "Command.CommandId")
          
          echo "SSM Command ID: $command_id"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"
          python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --command-id "$command_id" --output "false"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Reboot NB on Destination
        if: ${{ inputs.RestartDestinationEventstore == 'False' }}
        run: |
          command_id=$(aws ssm send-command \
                --document-name "${{ needs.setup-job-environment.outputs.DESTINATION_RESTART_NB_DOCUMENT_NAME }}" \
                --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.DestinationStackName }} \
                          Key=tag:role,Values=eventstore \
                --region ${{ needs.setup-job-environment.outputs.DESTINATION_REGION }} \
                --output text \
                --max-errors "100%" \
                --max-concurrency "100%" \
                --query "Command.CommandId")

          echo "SSM Command ID: $command_id"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}"
          python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.DESTINATION_REGION }}" --command-id "$command_id" --output "false"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Mark Account with Underscore on Source
        run: |
          command_id=$(aws ssm send-command \
                --document-name "${{ needs.setup-job-environment.outputs.UNDERSCORE_DOCUMENT_NAME }}" \
                --targets Key=tag:aws:cloudformation:stack-name,Values=${{ inputs.SourceStackName }} \
                          Key=tag:role,Values=eventstore \
                --region ${{ needs.setup-job-environment.outputs.SOURCE_REGION }} \
                --parameters '{"accountId":["${{ inputs.AccountId }}"]}' \
                --output text \
                --max-errors "100%" \
                --max-concurrency "100%" \
                --query "Command.CommandId")
          
          echo "SSM Command ID: $command_id"
          echo "SSM Run Command Link- https://${{ needs.setup-job-environment.outputs.SOURCE_REGION }}.console.aws.amazon.com/systems-manager/run-command/$command_id?region=${{ needs.setup-job-environment.outputs.SOURCE_REGION }}"
          python3 ./scripts/eventstore/check-ssm-output.py --region "${{ needs.setup-job-environment.outputs.SOURCE_REGION }}" --command-id "$command_id" --output "false"    
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

  correct-geo-data-in-profiles:
    runs-on: ${{ needs.setup-job-environment.outputs.DESTINATION_STACK_PREFIX }}
    needs:
      - setup-job-environment
      - execute-safety-check-before-migration
      - execute-eventstore-mongo-data-migration
      - wait-for-mongo-data-migration-complete
      - execute-disable-cron-jobs
      - wait-for-2-hour-and-approve-this
      - execute-stop-ingestion-and-validate-pausing-account
      - execute-source-account-migration-automation
      - wait-for-copy-all-account-to-s3-and-approve-this
      - execute-destination-account-migration-automation
      - wait-for-copy-all-accounts-to-destination-and-approve-this
      - validate-account-is-migrated-or-not
      - execute-post-account-migration-steps
    steps:
      - name: Checkout Infra-Actions repo
        uses: actions/checkout@v4
        with:
          show-progress: false

      - name: Checkout Cloudformation repo
        id: checkout-cloudformation-repo
        uses: actions/checkout@v3
        with:
          repository: CleverTap-SNE/Cloudformation
          path: cloudformation
          token: ${{ steps.generate-github-token.outputs.token }}

      - name: Install Python Requirements
        run: |
          set -euxo pipefail
          python3 -m venv prod-venv
          source prod-venv/bin/activate
          pip3 install requests argparse boto3 pymongo==4.6.3

      - name: get primary host ip
        id: get-primary-host-ip
        run: |
          set -euxo pipefail
          source prod-venv/bin/activate
          mongo_cluster_hosts=$(jq -r '.[] | select(.Name == "${{ needs.setup-job-environment.outputs.DESTINATION_STACK_PREFIX }}-Mongo-MetaData-1") .Instances[] | select(.EnableEc2instance == true and .StopServices == false) .PrivateIpAddress' cloudformation/mongo/${{ needs.setup-job-environment.outputs.DESTINATION_STACK_PREFIX }}/clusters.json | tr '\n' ',' | sed 's/,$//')
          primary_host=$(python3 ./scripts/mongo/get_primary_host.py --mongo-hosts $mongo_cluster_hosts)
          echo "PRIMARY_HOSTS=${primary_host}" >> $GITHUB_OUTPUT
        env:
          MONGO_INFRA_USER: ${{ secrets.MONGO_INFRA_USER }}
          MONGO_INFRA_PASSWORD: ${{ secrets.MONGO_INFRA_PASSWORD }}

      - name: Correct Geo Profile for Account Ids - ${{ inputs.AccountId }}
        run: |
          set -euxo pipefail
          source prod-venv/bin/activate
          python3 ./scripts/eventstore/mongo-data-migration.py --mongo-primary-ip ${{ steps.get-primary-host-ip.outputs.PRIMARY_HOSTS }} --task 5 --account-ids ${{ inputs.AccountId }}
        env:
          MONGO_INFRA_USER: ${{ secrets.MONGO_INFRA_USER }}
          MONGO_INFRA_PASSWORD: ${{ secrets.MONGO_INFRA_PASSWORD }}

